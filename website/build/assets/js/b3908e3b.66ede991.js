"use strict";(self.webpackChunk=self.webpackChunk||[]).push([[3482],{3905:(e,t,r)=>{r.d(t,{Zo:()=>c,kt:()=>f});var n=r(7294);function o(e,t,r){return t in e?Object.defineProperty(e,t,{value:r,enumerable:!0,configurable:!0,writable:!0}):e[t]=r,e}function a(e,t){var r=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),r.push.apply(r,n)}return r}function i(e){for(var t=1;t<arguments.length;t++){var r=null!=arguments[t]?arguments[t]:{};t%2?a(Object(r),!0).forEach((function(t){o(e,t,r[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(r)):a(Object(r)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(r,t))}))}return e}function p(e,t){if(null==e)return{};var r,n,o=function(e,t){if(null==e)return{};var r,n,o={},a=Object.keys(e);for(n=0;n<a.length;n++)r=a[n],t.indexOf(r)>=0||(o[r]=e[r]);return o}(e,t);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);for(n=0;n<a.length;n++)r=a[n],t.indexOf(r)>=0||Object.prototype.propertyIsEnumerable.call(e,r)&&(o[r]=e[r])}return o}var s=n.createContext({}),d=function(e){var t=n.useContext(s),r=t;return e&&(r="function"==typeof e?e(t):i(i({},t),e)),r},c=function(e){var t=d(e.components);return n.createElement(s.Provider,{value:t},e.children)},u="mdxType",l={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},m=n.forwardRef((function(e,t){var r=e.components,o=e.mdxType,a=e.originalType,s=e.parentName,c=p(e,["components","mdxType","originalType","parentName"]),u=d(r),m=o,f=u["".concat(s,".").concat(m)]||u[m]||l[m]||a;return r?n.createElement(f,i(i({ref:t},c),{},{components:r})):n.createElement(f,i({ref:t},c))}));function f(e,t){var r=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var a=r.length,i=new Array(a);i[0]=m;var p={};for(var s in t)hasOwnProperty.call(t,s)&&(p[s]=t[s]);p.originalType=e,p[u]="string"==typeof e?e:o,i[1]=p;for(var d=2;d<a;d++)i[d]=r[d];return n.createElement.apply(null,i)}return n.createElement.apply(null,r)}m.displayName="MDXCreateElement"},4811:(e,t,r)=>{r.r(t),r.d(t,{assets:()=>c,contentTitle:()=>s,default:()=>m,frontMatter:()=>p,metadata:()=>d,toc:()=>u});var n=r(7462),o=r(3366),a=(r(7294),r(3905)),i=["components"],p={id:"parquet",title:"Apache Parquet Extension"},s=void 0,d={unversionedId:"development/extensions-core/parquet",id:"development/extensions-core/parquet",title:"Apache Parquet Extension",description:"\x3c!--",source:"@site/../docs/development/extensions-core/parquet.md",sourceDirName:"development/extensions-core",slug:"/development/extensions-core/parquet",permalink:"/docs/development/extensions-core/parquet",draft:!1,editUrl:"https://github.com/apache/druid/edit/master/docs/../docs/development/extensions-core/parquet.md",tags:[],version:"current",lastUpdatedBy:"Jihoon Son",lastUpdatedAt:1579305125,formattedLastUpdatedAt:"Jan 17, 2020",frontMatter:{id:"parquet",title:"Apache Parquet Extension"},sidebar:"docs",previous:{title:"Druid pac4j based Security extension",permalink:"/docs/development/extensions-core/druid-pac4j"},next:{title:"PostgreSQL Metadata Store",permalink:"/docs/development/extensions-core/postgresql"}},c={},u=[],l={toc:u};function m(e){var t=e.components,r=(0,o.Z)(e,i);return(0,a.kt)("wrapper",(0,n.Z)({},l,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"This Apache Druid module extends ",(0,a.kt)("a",{parentName:"p",href:"/docs/ingestion/hadoop"},"Druid Hadoop based indexing")," to ingest data directly from offline\nApache Parquet files."),(0,a.kt)("p",null,"Note: If using the ",(0,a.kt)("inlineCode",{parentName:"p"},"parquet-avro")," parser for Apache Hadoop based indexing, ",(0,a.kt)("inlineCode",{parentName:"p"},"druid-parquet-extensions")," depends on the ",(0,a.kt)("inlineCode",{parentName:"p"},"druid-avro-extensions")," module, so be sure to\n",(0,a.kt)("a",{parentName:"p",href:"/docs/development/extensions#loading-extensions"},"include  both"),"."),(0,a.kt)("p",null,"The ",(0,a.kt)("inlineCode",{parentName:"p"},"druid-parquet-extensions")," provides the ",(0,a.kt)("a",{parentName:"p",href:"/docs/ingestion/data-formats#parquet"},"Parquet input format"),", the ",(0,a.kt)("a",{parentName:"p",href:"/docs/ingestion/data-formats#parquet-hadoop-parser"},"Parquet Hadoop parser"),",\nand the ",(0,a.kt)("a",{parentName:"p",href:"/docs/ingestion/data-formats#parquet-avro-hadoop-parser"},"Parquet Avro Hadoop Parser")," with ",(0,a.kt)("inlineCode",{parentName:"p"},"druid-avro-extensions"),".\nThe Parquet input format is available for ",(0,a.kt)("a",{parentName:"p",href:"/docs/ingestion/native-batch"},"native batch ingestion"),"\nand the other 2 parsers are for ",(0,a.kt)("a",{parentName:"p",href:"/docs/ingestion/hadoop"},"Hadoop batch ingestion"),".\nPlease see corresponding docs for details."))}m.isMDXComponent=!0}}]);